to a set of polynomials such that all the relations hold, it corresponds exactly one correct trace ?

We don't have such tests and I'm not sure how one would test for this, but looking at the way the traces are constructed I believe this is the case. There are several reasons for saying this.

First of all the connection with public data and the associated constraints will prove to the verifier that the prover only executed the transactions declared in the batch. There can be no stealth transactions. Stealth transaction would be a disaster as other operators would be incapable of computing the updated state.

Secondly, with the issues of stealth transactions out of the way, comes the question of the execution itself. Before touching upon execution one must settle the question of what bytecode is being run and whether there can be any ambiguity. Again my point is that there can not and if an ambiguity were to appear that we would be able to patch it with existing methods. The bytecode to be executed is given either (a) as public data (input data of the transaction used as initialization code in the execution) (b) bytecode previously committed to the state or (c) a slice of memory from an execution context which hits a CREATE(2) instruction that it can afford in terms of gas. The first case is covered by my earlier point about connecting the proof to public (block) data. The second case is about retrieving committed bytecode from the state. This will be handled by opening a commitment. The third case will be covered by my next point which is more general. Indeed, it touches upon executing individual instructions (of which RAM related opcodes and CREATEs are particular cases). I'll state my conclusion for that subcase right now: we can expect that the bytecode that's being run as initialization code of a CREATE(2) instruction is the expected one. There are quite a few subtleties that I'm brushing under the carpet about CREATE(2) in the presence of reverts which I won't get into them here

Thirdly, and lastly, the execution itself. For every relevant opcode its inputs/outputs appear as evaluations on the domain of at least one cell in the trace on the line(s) corresponding to the instruction. These inputs/outputs are funneled through to the relevant modules where outputs are justified. There are operations that are invisible on the stack (e.g. RAM operations such as RETURN that pop items off the stack but all the work happens in the background). In the case of RAM, for instance, the arguments of the various micro-instructions that in conjunction produce the desired effect (copying the relevant slice of bytes from one place to another, say) are checked by coherence conditions. For RAM the coherence conditions are simple: RAM is initially empty, and when a slice of 16 consecutive bytes (a limb) is touched at one point in time (serving either as a source of bytes or as a target in which to modify some bytes) then it produces a new value (e.g. VAL_A and VAL_A_NEW in the MMIO arithmetization) and the next time that slice of bytes is touched we expect to find in VAL_A what was previously written into VAL_A_NEW. Permutation arguments allow us to make this practical by grouping together all accesses to limbs in RAM in such a way that all RAM operations relative to a given execution context are contiguous, and within that all accesses to the limb with given offset are contiguous, and within that all accesses are ordered chronologically. This is the content of the "coherence checks" that was mentioned in one of the slides.

RAM is by far the most complicated case. Other operations are simpler: modules such as WORD_COMPARISON etc ... just perform standard boring operations whose arithmetization should be uncontroversial.

In any case, my final point is the following: other than for human mistakes in the arithmetization of certain operations the traces of individual modules are extractable: you can recover the inputs (and outputs if you want) of each and every instruction.